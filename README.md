<!--
 * @Author: Peng Wang
 * 
-->
# CLIPMulti

<img src="img/pytorch.png" width="10%"> [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) 

This repository contains the PyTorch implementation and the data of the paper: **CLIPMulti**.
[AAA](), [BBB](), [CCC](), [DDD]().  ***Journal of King Saud University - Computer and Information Sciences***.[[paper]]().



<!-- <div>
<img src="./img/SCIR_logo.png" width="100%">
</div> -->

## Current progress  

- [x] Submit paper
- [ ] Prepare code and push

## Prerequisites

This codebase was developed and tested with the following settings:

```
scikit-learn==1.2.1
numpy==1.24.2
pytorch==2.0.1
torchvision==0.15.2
tqdm==4.64.1
clip==1.0
transformers==4.27.1
regex==2022.10.31
ftfy==6.1.1
pillow==9.4.0
```

CLIP:

```shell
pip install git+https://github.com/openai/CLIP.git
```
